{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimum Birkhoff Decomposition: CPLEX Benchmark\n",
    "\n",
    "This notebook contains a short script to run the CPLEX experiments for the Minimum Birkhoff Decomposition problem: https://arxiv.org/abs/2504.03832 (Sec. 4.3.4).\n",
    "\n",
    "Select $n \\in \\{3,4,5,\\dots,16\\}$ and $\\text{type} \\in \\{\\text{sparse}, \\text{dense}\\}$. \n",
    "\n",
    "The maximum runtime per problem instance is limited to 3600 seconds. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/path/to/qoblib//qoblib-quantum-optimization-benchmarking-library/03-birkhoff/instances/qbench_4_sparse.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Load data\u001b[39;00m\n\u001b[1;32m     17\u001b[0m file_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mPATH_TO_QOBLIB\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/qoblib-quantum-optimization-benchmarking-library/03-birkhoff/instances/qbench_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(n) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mtype\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 18\u001b[0m data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Output dataframe \u001b[39;00m\n\u001b[1;32m     21\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstance\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecomposition_length\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecomposition_error\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/my_env/lib/python3.8/site-packages/IPython/core/interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m     )\n\u001b[0;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/path/to/qoblib//qoblib-quantum-optimization-benchmarking-library/03-birkhoff/instances/qbench_4_sparse.json'"
     ]
    }
   ],
   "source": [
    "import numpy as np, pandas as pd\n",
    "import json, time\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "sys.path.append(\"src\")\n",
    "import model\n",
    "\n",
    "# Setup \n",
    "n = 4                                       # size of the doubly stochastic matrix\n",
    "type = \"sparse\"                             # sparse or dense\n",
    "PATH_TO_QOBLIB = "/path/to/qoblib/"         # QOBLIB folder: https://git.zib.de/qopt/qoblib-quantum-optimization-benchmarking-library
    "LOGS_FOLDER = 'logs'                        # output folder\n",
    "\n",
    "# Load data\n",
    "file_name = f'{PATH_TO_QOBLIB}/qoblib-quantum-optimization-benchmarking-library/03-birkhoff/instances/qbench_' + str(n) + '_' + type + '.json'\n",
    "data = json.load(open(file_name))\n",
    "\n",
    "# Output dataframe \n",
    "df = pd.DataFrame(columns = [\"instance\", \"decomposition_length\", \"decomposition_error\", \"time\"])\n",
    "\n",
    "for i in tqdm(range(1, 11)):\n",
    "    \n",
    "    x_star = np.array(data[str(i)]['scaled_doubly_stochastic_matrix'])\n",
    "    Birk = model.BirkCplex(x_star)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    status, permutations, weights = Birk.solve()\n",
    "    \n",
    "    if(status=='success'):\n",
    "        algorithm_runtime = time.time() - start_time\n",
    "        perm_list = np.reshape(permutations,(len(weights),n,n)) \n",
    "        recovered_matrix = np.zeros((n,n))\n",
    "        for m in range(0,len(perm_list)):\n",
    "            recovered_matrix = recovered_matrix + weights[m] * perm_list[m] \n",
    "\n",
    "        recovered_matrix = recovered_matrix / sum(weights)\n",
    "\n",
    "        error  = recovered_matrix - np.reshape(x_star, (n,n)) / sum(weights)\n",
    "        norm_error = np.linalg.norm(error, ord='fro')\n",
    "        \n",
    "        df.loc[i] = [str(i), len(weights), norm_error, algorithm_runtime]\n",
    "\n",
    "Path(f'{LOGS_FOLDER}').mkdir(parents=True, exist_ok=True)\n",
    "df.to_csv(f'{LOGS_FOLDER}/' + str(n) + '_' + type + '.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
